{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6Eq6KHHEVBV"
   },
   "source": [
    "# Ainda sobre Regularização... Vamos falar sobre árvores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOO2i_BvEVBa"
   },
   "source": [
    "\n",
    "Nossas últimas aulas falaram sobre regularização, cujo intuito é reduzir a variância dos modelos, fazendo com que esses sejam menos vulneráveis em relação ao overfitting.\n",
    "Até aqui, vimos como alterar a função de erro do gradiente descendente. Hoje, falaremos um pouco sobre os hiperparâmetos das árvores de decisão e como que a escolha de cada um deles afeta a estrutura da árvore e está ligada ao overfitting. Ao fim, veremos como podar nossa árvore para melhorar a sua generalização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjQc3A-AEVBb"
   },
   "source": [
    "# Pré-Prunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yptOvDRlEVBd"
   },
   "source": [
    "## criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rllbr38OEVBd"
   },
   "source": [
    "Quando estudamos o processo de desenvolvimento/treinamento das árvores de decisão, falamos que elas baseavam-se em critérios de divisão e estes eram basicamente dois: entropia e gini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5sNGapPEVBe"
   },
   "source": [
    "<img src=\"https://miro.medium.com/max/852/0*9ORK1-MuC7FEcsiq\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0t7sUYN5EVBe"
   },
   "source": [
    "Por padrão, esse parâmetro é definido como ```criterion=gini```. Não é um hiperparâmetro tão decisivo para a performance das árvores. O método de entropia, por sua vez, é mais demorado. Na prática, não precisaremos ajustar esse hiperparâmetro, poderemos deixar o padrão.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yo3zZsEkEVBf"
   },
   "source": [
    "## splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7PG5ws8EVBg"
   },
   "source": [
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ4HyvKCW_FajF1og2nAmhn-5d38VlqSAj7YQ&usqp=CAU\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7604li4EVBh"
   },
   "source": [
    "Esse hiperparâmetro traz 2 opções: ```best``` e ```random```. Na opção best, as features escolhidas para cada nó são aquelas cujo ganho de informação seja maior/redução de entropia/redução de impureza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0H4jcsXEVBj"
   },
   "source": [
    "A única diferença é que no divisor ```best``` ele avalia todas as divisões usando o critério antes da divisão, enquanto o divisor ```random``` usa uma função uniforme aleatória com ```min_feature_value```, ```max_feature_value``` e ```random_state```  de entradas. \n",
    "\n",
    "Digamos que você tenha centenas de features, então o divisor ```best``` seria ideal porque ele calculará as melhores features para dividir com base na medida de impureza e usará isso para dividir os nós, ao passo que se você escolher ```random``` terá uma grande chance de acabar com features que realmente não fornecem tanta informação, o que levaria a uma árvore mais profunda e menos precisa.\n",
    "Por outro lado, o divisor ```random``` tem algumas vantagens, especificamente, uma vez que seleciona um conjunto de features aleatoriamente e divide, ele não tem a sobrecarga computacional de calcular a divisão ideal. Além disso, também é menos sujeito a overfitting porque você não está essencialmente calculando a melhor divisão antes de cada divisão e a aleatoriedade adicional o ajudará aqui, então, se seu modelo estiver overfitando, você pode alterar o divisor para ```random``` e treinar novamente.\n",
    "Portanto, para uma árvore com poucos recursos sem nenhum ajuste excessivo, eu escolheria o divisor ```best``` para garantir que você obtenha a melhor arquitetura de modelo possível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGqgbVbCEVBk"
   },
   "source": [
    "## max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjLb_m1tEVBk"
   },
   "source": [
    "<img src=\"https://miro.medium.com/max/1990/1*tMU0XhEbj5aKgGt9RX-UQQ.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0hu37M1EVBl"
   },
   "source": [
    "O hiperparâmetro ```max_depth``` define a profundidade máxima da árvore. Por padrão, nenhuma profundidade máxima é definida e isso leva ao overfitting, pois as folhas são completamente puras, ao ponto de cada folha conter apenas uma única instância. A árvore cresce indefinidamente até que todas as folhas sejam puras ou até que todas as folhas contenham menos do que min_samples_split amostras (número mínimo de amostras em um nó para o nó poder sofrer divisão).\n",
    "A profundidade máxima teórica que uma árvore de decisão pode atingir é um a menos que o número de amostras de treinamento, mas nenhum algoritmo permitirá que você chegue a esse ponto por razões óbvias, uma das grandes razões é o overfitting. Observe aqui que é o número de amostras de treinamento e não o número de recursos, porque os dados podem ser divididos no mesmo recurso várias vezes.\n",
    "\n",
    "Em geral, quanto mais profundo você permite que sua árvore cresça, mais complexo seu modelo se tornará, porque você terá mais divisões e captura mais informações sobre os dados e esta é uma das principais causas do sobreajuste em árvores de decisão porque seu modelo irá se encaixam perfeitamente para os dados de treinamento e não serão capazes de generalizar bem no conjunto de teste. Portanto, se o seu modelo estiver com overfitting, reduzir o número de ```max_depth``` é uma forma de combater o overfitting.\n",
    "\n",
    "Também é ruim ter uma profundidade muito baixa porque seu modelo será insuficiente para encontrar o melhor valor, experimente porque overfitting e underfitting são muito subjetivos para um conjunto de dados, não há um valor único para todas as soluções. Então, o que eu geralmente faço é deixar o modelo decidir primeiro max_depth e, em seguida, comparando minhas pontuações de treinamento e teste, procuro overfitting ou underfitting e, dependendo do grau, diminuo ou aumento a ```max_depth```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "va_1_zAGEVBl"
   },
   "source": [
    "## min_samples_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5evtLmYQEVBm"
   },
   "source": [
    "<img src=\"https://gblobscdn.gitbook.com/assets%2F-LagOeJ2nL90MQERwhxy%2F-LjmGR4-Zkpsp-CXV3zt%2F-Lk-zrrQar1T7mfpJ4jY%2Fimage.png?alt=media&token=75b26a95-2227-4832-8860-8e1086a4743b\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFPgFDE0EVBm"
   },
   "source": [
    "```min_samples_split``` é o número mínimo de amostras em cada nó, necessárias para que haja um split. Se, por exemplo, definirmos ```min_samples_split``` como 11, isso significa que o nó só poderá se dividir, caso haja pelo menos 11 amostras nele. Caso contrário, esse nó  é transformado em folha. Por padrão,  o modelo inicializa com o valor 2. Estudos mostram que o valor ideal pode estar entre 2 e 40 para o algoritmo CART, o qual é implementado no ```scikit-learn```. Esse parâmetro é um dos responsáveis por controlar o overfitting. Valores altos ajudam a previnir o overfitting, isso pois ajudará o modelo a não aprender relações que sejam específicas de uma amostra em particular ou de um conjunto de amostras (que podem ser ruído). Em contrapartida, valores muito altos podem levar a underfitting. Dependendo do nível de ovefitting e underfitting, poderemos ajustar esse valor até achar o melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1ygAZQsEVBn"
   },
   "source": [
    "Também podemos passar um número float para ele e então o modeo entenderá que o ```min_samples_split``` a ser utilizado é ```ceil(min_samples_split * n_samples)``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBqD-WSjEVBo"
   },
   "source": [
    "## min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbdCCvzHEVBo"
   },
   "source": [
    "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/Screenshot-2020-03-04-at-15.34.46.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5P-_lEfhEVBo"
   },
   "source": [
    "O número mínimo de amostras necessárias para estar em um nó folha. Um ponto de divisão em qualquer profundidade só será considerado se deixar pelo menos min_samples_leaf amostras de treinamento em cada um dos ramos esquerdo e direito. Isso pode ter o efeito de suavizar o modelo, especialmente na regressão.\n",
    "Se int, considere min_samples_leaf como o número mínimo.\n",
    "Se float, então min_samples_leaf é uma fração e ceil (min_samples_leaf * n_samples) é o número mínimo de amostras para cada nó.\n",
    "Semelhante a ```min_samples_split```, ```min_samples_leaf``` também é usado para controlar o sobreajuste, definindo que cada folha tem mais de um elemento. Assim, garantindo que a árvore não supere o conjunto de dados de treinamento, criando um monte de pequenos ramos exclusivamente para uma amostra cada. Na realidade, o que isso está realmente fazendo é simplesmente dizer à árvore que cada folha não precisa ter uma impureza de 0.\n",
    "O artigo, Um estudo empírico sobre ajuste de hiperparâmetros de árvores de decisão [5], também afirma que os valores min_samples_leaf ideais tendem a estar entre 1 a 20 para o algoritmo CART. Este artigo também indica que min_samples_split e min_samples_leaf são os maiores responsáveis ​​pelo desempenho das árvores finais de sua análise de importância relativa.\n",
    "De acordo com o scikit-learn, podemos usar min_samples_split ou min_samples_leaf para garantir que várias amostras informem todas as decisões na árvore, controlando quais divisões serão consideradas. Eles também dizem que um número muito pequeno geralmente significa que a árvore se ajustará demais, enquanto um número grande impedirá que a árvore aprenda os dados e isso deve fazer sentido. Acho que uma exceção a isso é quando você tem um problema de classe desequilibrada, porque então as regiões em que a classe minoritária estará em maioria serão muito pequenas, então você deve escolher um valor mais baixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QS9RkoDvEVBo"
   },
   "source": [
    "# Pós Prunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLS6csz-EVBo"
   },
   "source": [
    "As árvores de decisão estão sujeitas a ajustes excessivos. As técnicas de poda garantem que as árvores de decisão tendam a generalizar melhor os dados \"não vistos\". Uma árvore de decisão pode ser podada antes ou / e depois de construí-la. No entanto, qualquer um dos métodos de poda é suficiente para remover o sobreajuste. A pós-poda é uma forma mais científica de podar árvores de decisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_nIJBmeEVBp"
   },
   "source": [
    "Essa \"técnica de regularizaçao\" \"poda\" a árvore depois que ela crescer totalmente. Ele remove uma subárvore e a substitui por um nó folha, a classe mais frequente da subárvore determina o rótulo da nova folha. Esse parâmetro é controlado no sklearn pelo hyperparâmetro ccp_alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFJWbf5mEVBr"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DSTN02 - Regularização II.ipynb",
   "provenance": [
    {
     "file_id": "16fCtHPOuNtQ8OLeC16hEzy_q-xI3byXB",
     "timestamp": 1624918513833
    },
    {
     "file_id": "1aVp9Xet51q-XSt3bvevF92H2n3ftYNc5",
     "timestamp": 1624916910981
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "nteract-on-jupyter@1.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
